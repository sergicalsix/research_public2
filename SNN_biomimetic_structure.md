#題名
[paper](https://ieeexplore.ieee.org/abstract/document/9407642)

<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
 tex2jax: {
 inlineMath: [['$', '$'] ],
 displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
 }
 });
</script>
## Abstruct

スパイキングニューラルネットワーク（SNN）は、脳にヒントを得た新しい人工ニューラルネットワークの計算モデルであり、複雑な時空間情報を低消費電力で処理するのに適したツールである。しかし、SNNは不連続かつ非微分のメカニズムを持ち、計算モデルが複雑なため、学習プロセスが難しく、学習効率が低いという課題があります。本論文では，生体神経系の自己組織化プロセスにヒントを得て，シナプス前ニューロンとシナプス後ニューロンのスパイク時間差に基づいた，一種の生体模倣構造学習アルゴリズムを提案する．本論文では、リーキーインテグレートアンドファイア（LIF）ニューロンとコンダクタンスベースのシナプスを用い、スパイク時間依存可塑性（STDP）学習規則に基づいて、4層のフィードフォワードネットワークを構築します。完全連結型ネットワークとは異なり、シナプス前とシナプス後のニューロン間の正確なスパイク時間差に基づいて、ネットワークの学習中にニューロン間の新しい接続を確立する方法を提案しています。また、ネットワークの学習機能の特異性を確保するために、出力層にWinner-take-all（WTA）競争メカニズムを導入しています。実験の結果，MNISTデータセットを用いた場合，我々のネットワークの分類能力は92.1%を達成した．また、完全連結型SNNと比較して、学習時間が2.6時間と大幅に短縮され、完全連結型ネットワークの82%を占めることがわかった。最後に、関連する実験データと合わせて、SNNの消費電力がANNよりもはるかに小さいことも証明しています。



## Intro
